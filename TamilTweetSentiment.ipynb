{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2df00a9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1015 entries, 0 to 1014\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet      1015 non-null   object\n",
      " 1   sentiment  1015 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 16.0+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#import dataset from local device\n",
    "tweet_data = pd.read_csv('./Data/tweet.csv')\n",
    "tweet_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca16805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>உன்னைத்தொட்டால் உன்னுள்ளத்தை நொருக்கமாட்டியோ!!...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>உறக்கம் விற்று கனவுகள் வாங்கலையா?! #TamilLyric...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>மீண்டும் உன்னை காணும் மனமே ... வேண்டும் எனக்கே...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>உயிரை தொலைத்தேன் அது உன்னில் தானோ ... இது நான்...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ஒரு வீதி பத்தாதே. ஊரு பத்தாதே. நாம இறங்கி கலக்...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>அழகளந்திடும் கருவிகள்\\r\\nசெயலிழந்திடும் அவளிடம...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>அழகான மனைவி, அன்பான துணைவி, அமைந்தாலே பேரின்பம...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ஒரே ஒரு பார்வை தந்தாலென்ன தேனே  \\r\\nஒரே ஒரு வா...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>அவள் சிக்கெடுக்கும் கூந்தலுக்கு சீப்பாக இருப்ப...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ஓரிரு வார்த்தை தப்பாய் போனால் உதடு கடிப்பாய்… ...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0  உன்னைத்தொட்டால் உன்னுள்ளத்தை நொருக்கமாட்டியோ!!...     Happy\n",
       "1  உறக்கம் விற்று கனவுகள் வாங்கலையா?! #TamilLyric...       Sad\n",
       "2  மீண்டும் உன்னை காணும் மனமே ... வேண்டும் எனக்கே...       Sad\n",
       "3  உயிரை தொலைத்தேன் அது உன்னில் தானோ ... இது நான்...       Sad\n",
       "4  ஒரு வீதி பத்தாதே. ஊரு பத்தாதே. நாம இறங்கி கலக்...     Happy\n",
       "5  அழகளந்திடும் கருவிகள்\\r\\nசெயலிழந்திடும் அவளிடம...     Happy\n",
       "6  அழகான மனைவி, அன்பான துணைவி, அமைந்தாலே பேரின்பம...     Happy\n",
       "7  ஒரே ஒரு பார்வை தந்தாலென்ன தேனே  \\r\\nஒரே ஒரு வா...       Sad\n",
       "8  அவள் சிக்கெடுக்கும் கூந்தலுக்கு சீப்பாக இருப்ப...       Sad\n",
       "9  ஓரிரு வார்த்தை தப்பாய் போனால் உதடு கடிப்பாய்… ...     Happy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample data from the data frame\n",
    "tweet_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e410a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet        0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a92049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sad      509\n",
      "Happy    506\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tweet_data['sentiment'].value_counts())\n",
    "sns.countplot(x=tweet_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4e0708",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4abbe2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\abi\\anaconda3\\lib\\site-packages (1.6.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c6b14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  \n",
    "import string\n",
    "import emoji\n",
    "\n",
    "def clean(tweet):\n",
    "    cleaned = re.sub(r'[a-zA-Z0-9]',' ',tweet)\n",
    "    cleaned = re.sub('\\s',' ',cleaned)\n",
    "    cleaned = re.sub(r'_',' ',cleaned)\n",
    "    cleaned = re.sub(r'…','',cleaned)\n",
    "    cleaned =\"\".join([t for t in cleaned if t not in string.punctuation])\n",
    "    cleaned = emoji.demojize(cleaned, delimiters=(\" \", \" \"))\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f416b275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>காலை வணக்கம் .......🥰🥰🥰🥰\\r\\nஅன்பு நண்பர்களே .....</td>\n",
       "      <td>Happy</td>\n",
       "      <td>காலை வணக்கம்  smiling_face_with_hearts  smilin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>🎼அன்பை_அளந்திட_எந்த_மொழியும்_போதாது...😍❤😍❤😍❤\\r...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>musical_score அன்பை அளந்திட எந்த மொழியும் போத...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>மழைக்கால அணைக்கட்டாய்\\r\\nமனதிற்குள் தளும்பிக்க...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>மழைக்கால அணைக்கட்டாய்  மனதிற்குள் தளும்பிக்கொண...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>மீள்பகிர்வு: இங்கே கொரோனா\\r\\nதொற்று நாளுக்குநா...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>மீள்பகிர்வு இங்கே கொரோனா  தொற்று நாளுக்குநாள் ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>அவள் சிக்கெடுக்கும் கூந்தலுக்கு சீப்பாக இருப்ப...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>அவள் சிக்கெடுக்கும் கூந்தலுக்கு சீப்பாக இருப்ப...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>எண்ணம் முழுவதும் \\r\\nநீயே எங்கும் ,\\r\\nஉன்னை க...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>எண்ணம் முழுவதும்   நீயே எங்கும்   உன்னை காண   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>அன்பு ஒன்று தான் அநாதை\\r\\nபாசம் ஒன்று தான் பரு...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>அன்பு ஒன்று தான் அநாதை  பாசம் ஒன்று தான் பருப்...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>அரசுக்கு பணம் தான் முக்கியம், பல்லி இருந்து கு...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>அரசுக்கு பணம் தான் முக்கியம் பல்லி இருந்து குட...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>நாடே கொண்டாட்டத்துல இருக்கு, நீங்க என்னங்க இப்...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>நாடே கொண்டாட்டத்துல இருக்கு நீங்க என்னங்க இப்ப...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>எல்லா பிரச்சினை யும் முடிந்தது..\\r\\n#சிம்பு அண...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>எல்லா பிரச்சினை யும் முடிந்தது  சிம்பு அண்ணா அ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet sentiment  \\\n",
       "735  காலை வணக்கம் .......🥰🥰🥰🥰\\r\\nஅன்பு நண்பர்களே .....     Happy   \n",
       "108  🎼அன்பை_அளந்திட_எந்த_மொழியும்_போதாது...😍❤😍❤😍❤\\r...     Happy   \n",
       "389  மழைக்கால அணைக்கட்டாய்\\r\\nமனதிற்குள் தளும்பிக்க...     Happy   \n",
       "930  மீள்பகிர்வு: இங்கே கொரோனா\\r\\nதொற்று நாளுக்குநா...       Sad   \n",
       "8    அவள் சிக்கெடுக்கும் கூந்தலுக்கு சீப்பாக இருப்ப...       Sad   \n",
       "90   எண்ணம் முழுவதும் \\r\\nநீயே எங்கும் ,\\r\\nஉன்னை க...       Sad   \n",
       "360  அன்பு ஒன்று தான் அநாதை\\r\\nபாசம் ஒன்று தான் பரு...     Happy   \n",
       "791  அரசுக்கு பணம் தான் முக்கியம், பல்லி இருந்து கு...       Sad   \n",
       "641  நாடே கொண்டாட்டத்துல இருக்கு, நீங்க என்னங்க இப்...       Sad   \n",
       "338  எல்லா பிரச்சினை யும் முடிந்தது..\\r\\n#சிம்பு அண...     Happy   \n",
       "\n",
       "                                               cleaned  \n",
       "735  காலை வணக்கம்  smiling_face_with_hearts  smilin...  \n",
       "108   musical_score அன்பை அளந்திட எந்த மொழியும் போத...  \n",
       "389  மழைக்கால அணைக்கட்டாய்  மனதிற்குள் தளும்பிக்கொண...  \n",
       "930  மீள்பகிர்வு இங்கே கொரோனா  தொற்று நாளுக்குநாள் ...  \n",
       "8    அவள் சிக்கெடுக்கும் கூந்தலுக்கு சீப்பாக இருப்ப...  \n",
       "90   எண்ணம் முழுவதும்   நீயே எங்கும்   உன்னை காண   ...  \n",
       "360  அன்பு ஒன்று தான் அநாதை  பாசம் ஒன்று தான் பருப்...  \n",
       "791  அரசுக்கு பணம் தான் முக்கியம் பல்லி இருந்து குட...  \n",
       "641  நாடே கொண்டாட்டத்துல இருக்கு நீங்க என்னங்க இப்ப...  \n",
       "338  எல்லா பிரச்சினை யும் முடிந்தது  சிம்பு அண்ணா அ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['cleaned'] = tweet_data['tweet'].map(clean)\n",
    "\n",
    "tweet_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "892343c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('பாசம்', 376),\n",
       " ('என்', 162),\n",
       " ('காதல்', 150),\n",
       " ('தான்', 137),\n",
       " ('அன்பு', 129),\n",
       " ('ஒரு', 127),\n",
       " ('smiling_face_with_heart-eyes', 123),\n",
       " ('red_heart', 119),\n",
       " ('மழை', 118),\n",
       " ('நீ', 113),\n",
       " ('சோகம்', 102),\n",
       " ('நான்', 93),\n",
       " ('உன்', 93),\n",
       " ('இந்த', 67),\n",
       " ('இல்லை', 62),\n",
       " ('folded_hands', 58),\n",
       " ('என்ன', 56),\n",
       " ('fire', 54),\n",
       " ('என்று', 53),\n",
       " ('பணம்', 52)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "cleaned_text = tweet_data['cleaned'].str.cat(sep=' ')\n",
    "splited = cleaned_text.split()\n",
    "most_common = (collections.Counter(splited)).most_common(20)\n",
    "most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb4ce8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweet_data['cleaned']\n",
    "y = tweet_data['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a434635f",
   "metadata": {},
   "source": [
    "# Tamil stopwords removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "153a2bb9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ஒரு', 'என்று', 'மற்றும்', 'இந்த', 'இது', 'என்ற', 'கொண்டு', 'என்பது', 'பல', 'ஆகும்']\n"
     ]
    }
   ],
   "source": [
    "my_file = open(\"./Data/TamilStopWords.txt\", encoding=\"utf8\")\n",
    "content = my_file.read()\n",
    "content_list = content.split(\"\\n\")\n",
    "my_file.close()\n",
    "\n",
    "print(content_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f68681",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15e4d573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "சிந்தனையில் வந்துவந்து போறா  அவ சந்தனத்தில் செஞ்சுவெச்ச தேரா             \n",
      "  (0, 614)\t0.14863509574262085\n",
      "  (0, 950)\t0.4162754754196546\n",
      "  (0, 494)\t0.4432250950687617\n",
      "  (0, 481)\t0.2312448056912999\n",
      "  (0, 486)\t0.43247811171546646\n",
      "  (0, 467)\t0.5873097372776035\n",
      "  (0, 471)\t0.15076354733734357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abi\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['அங', 'அட', 'அத', 'அதன', 'அதற', 'அந', 'அன', 'அல', 'அவ', 'அவன', 'அவர', 'அவரத', 'அவள', 'ஆக', 'இங', 'இடத', 'இடம', 'இத', 'இதன', 'இதற', 'இந', 'இன', 'இப', 'இர', 'இவ', 'இவர', 'உன', 'உள', 'எந', 'எனக', 'எனப', 'எனவ', 'எல', 'ஏன', 'ஒர', 'ஓர', 'கள', 'கவ', 'சற', 'தக', 'தத', 'தன', 'தனத', 'தப', 'தல', 'தவ', 'னர', 'பட', 'பத', 'பற', 'பலர', 'மட', 'மற', 'றக', 'லத', 'ளத', 'ளன', 'வந', 'வர'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features= 1000,  stop_words = content_list)\n",
    "X_vectors = vectorizer.fit_transform(X)\n",
    "\n",
    "\n",
    "print(X[11])\n",
    "print(X_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0afa91",
   "metadata": {},
   "source": [
    "# Choosing best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83ef04c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialze the estimators\n",
    "clf1 = RandomForestClassifier(random_state=42)\n",
    "clf2 = SVC(probability=True, random_state=42)\n",
    "clf3 = LogisticRegression(random_state=42)\n",
    "clf4 = DecisionTreeClassifier(random_state=42)\n",
    "clf5 = KNeighborsClassifier()\n",
    "clf6 = MultinomialNB()\n",
    "clf7 = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Initiaze the hyperparameters for each dictionary\n",
    "param1 = {}\n",
    "param1['classifier__n_estimators'] = [10, 50, 100, 250]\n",
    "param1['classifier__max_depth'] = [5, 10, 20]\n",
    "param1['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "param1['classifier'] = [clf1]\n",
    "\n",
    "param2 = {}\n",
    "param2['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "param2['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "param2['classifier'] = [clf2]\n",
    "\n",
    "param3 = {}\n",
    "param3['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "param3['classifier__penalty'] = ['l1', 'l2']\n",
    "param3['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "param3['classifier'] = [clf3]\n",
    "\n",
    "param4 = {}\n",
    "param4['classifier__max_depth'] = [5,10,25,None]\n",
    "param4['classifier__min_samples_split'] = [2,5,10]\n",
    "param4['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "param4['classifier'] = [clf4]\n",
    "\n",
    "param5 = {}\n",
    "param5['classifier__n_neighbors'] = [2,5,10,25,50]\n",
    "param5['classifier'] = [clf5]\n",
    "\n",
    "param6 = {}\n",
    "param6['classifier__alpha'] = [10**0, 10**1, 10**2]\n",
    "param6['classifier'] = [clf6]\n",
    "\n",
    "param7 = {}\n",
    "param7['classifier__n_estimators'] = [10, 50, 100, 250]\n",
    "param7['classifier__max_depth'] = [5, 10, 20]\n",
    "param7['classifier'] = [clf7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00090a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('classifier', clf1)])\n",
    "params = [param1, param2, param3, param4, param5, param6, param7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2795d2f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.62561576 0.6955665  0.7182266  0.72413793 0.69359606 0.72906404\n",
      " 0.73596059 0.73891626 0.69655172 0.73300493 0.74581281 0.74384236\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.50147783        nan        nan        nan 0.51527094        nan\n",
      "        nan        nan 0.72807882        nan        nan        nan\n",
      " 0.73103448        nan        nan        nan 0.73103448        nan\n",
      "        nan        nan        nan 0.68965517        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.72019704\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.73300493        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.72512315        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.70640394\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62364532 0.62167488 0.62167488 0.6453202  0.65320197 0.65320197\n",
      " 0.6729064  0.67192118 0.66502463 0.64729064 0.66305419 0.65812808\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.55073892 0.67389163 0.67586207 0.7044335  0.69064039 0.73103448\n",
      " 0.73497537 0.70837438 0.71034483 0.72019704 0.71527094 0.72315271\n",
      " 0.70246305 0.72413793 0.7320197  0.70935961 0.70246305 0.71428571\n",
      " 0.72512315 0.72315271]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(pipeline, params, cv=5, n_jobs=-1, scoring).fit(X_vectors, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2100c8b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': RandomForestClassifier(max_depth=20, random_state=42), 'classifier__class_weight': None, 'classifier__max_depth': 20, 'classifier__n_estimators': 100}\n",
      "0.7458128078817734\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_params_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d45070",
   "metadata": {},
   "source": [
    "# Creating final model with selected parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17f22670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7458128078817734\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier gave best score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "final_model = RandomForestClassifier(max_depth=20, random_state=42, n_estimators= 100)\n",
    "print(cross_val_score(final_model, X_vectors, y, cv = 5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58a030e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.80      0.44      0.57       102\n",
      "         Sad       0.61      0.89      0.73       101\n",
      "\n",
      "    accuracy                           0.67       203\n",
      "   macro avg       0.71      0.67      0.65       203\n",
      "weighted avg       0.71      0.67      0.65       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.73      0.79      0.76       101\n",
      "         Sad       0.77      0.71      0.74       102\n",
      "\n",
      "    accuracy                           0.75       203\n",
      "   macro avg       0.75      0.75      0.75       203\n",
      "weighted avg       0.75      0.75      0.75       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.71      0.65      0.68       101\n",
      "         Sad       0.68      0.74      0.71       102\n",
      "\n",
      "    accuracy                           0.69       203\n",
      "   macro avg       0.70      0.69      0.69       203\n",
      "weighted avg       0.70      0.69      0.69       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.82      0.91      0.86       101\n",
      "         Sad       0.90      0.80      0.85       102\n",
      "\n",
      "    accuracy                           0.86       203\n",
      "   macro avg       0.86      0.86      0.86       203\n",
      "weighted avg       0.86      0.86      0.86       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.90      0.59      0.71       101\n",
      "         Sad       0.70      0.93      0.80       102\n",
      "\n",
      "    accuracy                           0.76       203\n",
      "   macro avg       0.80      0.76      0.76       203\n",
      "weighted avg       0.80      0.76      0.76       203\n",
      "\n",
      "[0.66502463 0.74876847 0.69458128 0.85714286 0.7635468 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "\n",
    "    print(classification_report(y_true, y_pred)) # print classification report\n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "nested_score = cross_val_score(final_model, X=X_vectors, y=y, cv=5, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(nested_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f48a69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sad', 'Sad'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X_vectors,y)\n",
    "test_set = ['அருகில் இருந்தும் காதல் பிாிவில் பெருகிடுமே','உன் நெனப்புல நான் வாட என் உசுருல நீ தேட']\n",
    "new_test = vectorizer.transform(test_set)\n",
    "\n",
    "final_model.predict(new_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
